#! %rax = %%rax
#! %rdx = %%rdx
#! %rcx = %%rcx
#! %rbp = %%rbp
#! %r8 = %%r8
#! %r9 = %%r9
#! %r10 = %%r10
#! %r11 = %%r11
#! %r12 = %%r12
#! %r13 = %%r13
#! %r14 = %%r14
#! %r15 = %%r15
#! %r8  = %%r8
#! %eax = %%eax
#! -0x80(%rsi) = %%EA
#! 0x80(%rsi) = %%EA
#! 0x88(%rsi) = %%EA
#! 0x90(%rsi) = %%EA
#! 0x98(%rsi) = %%EA
#! 0x8(%rsi) = %%EA
#! 0x10(%rsi) = %%EA
#! 0x18(%rsi) = %%EA
#! (%rsi) = %%EA
#! %rsi = %%rsi
#! -0xccf(%rip) = %%EA
#! -0xd6b(%rip) = %%EA

#! add $1v, $2v -> bvAddC carry ($2v) (bvVar ($1v)) (bvVar ($2v))
#! add $1c, $2v -> bvAddC carry ($2v) (bvConst (fromPosZ ($1c))) (bvVar ($2v))
#! adc $1v, $2v -> bvAdcC carry ($2v) (bvVar ($1v)) (bvVar ($2v)) (carry)
#! adc $1c, $2v -> bvAdcC carry ($2v) (bvConst (fromPosZ ($1c))) (bvVar ($2v)) (carry)
#! adc \$0x0, $1v -> bvAdc ($1v) (bvVar ($1v)) (bvConst (fromPosZ 0%Z)) (carry)
#! mul $1v -> bvMulf rdx rax (bvVar ($1v)) (bvVar rax)
#! mov $1v, $2v -> bvAssign ($2v) (bvVar ($1v))
#! mov \$0x20, $1v -> bvAssign ($1v) (bvConst (fromPosZ 32%Z))
#! xor $1v, $1v -> bvAssign ($1v) (bvConst (fromPosZ 0%Z));\nbvAssign (carry) (bvConst (fromPosZ 0%Z));\nbvAssign (overflow) (bvConst (fromPosZ 0%Z))
# NOTE: %rsi is always $0x20 for shlx and shrx
#! shlx %%rsi, $1v, $2v -> bvShl ($2v) (bvVar ($1v)) (fromNat 32)
#! shrx %%rsi, $1v, $2v -> bvSplit ($2v) tmp (bvVar ($1v)) (fromNat 32)
#! mulx $1v, $2v, $3v -> bvMulf ($3v) ($2v) (bvVar ($1v)) (bvVar rdx)
#! addr32 mulx $1v, $2v, $3v -> bvMulf ($3v) ($2v) (bvVar ($1v)) (bvVar rdx)
#! addr32 addr32 mulx $1v, $2v, $3v -> bvMulf ($3v) ($2v) (bvVar ($1v)) (bvVar rdx)
#! adcx $1v, $2v -> bvAdcC carry ($2v) (bvVar ($1v)) (bvVar ($2v)) (carry)
#! adox $1v, $2v -> bvAdcC overflow ($2v) (bvVar ($1v)) (bvVar ($2v)) (overflow)

#ecp_nistz256_sqr_mont:
# %rdi = 0x7fffffffd6d0
# %rsi = 0x62c080
# %rdx = 0x7fffffffd7f8
# %rcx = 0x0
# %r8  = 0x0
# %r9  = 0x-5cdfd00000000
#	mov    $0x80100,%ecx
#	and    0x204949(%rip),%ecx        # 0x62c0b4 <OPENSSL_ia32cap_P+8>#! EA = L0x62c0b4
#	push   %rbp
#	push   %rbx
#	push   %r12
#	push   %r13
#	push   %r14
#	push   %r15
#	cmp    $0x80100,%ecx
#	#je     0x4277a0 <ecp_nistz256_sqr_mont+64>
	mov    (%rsi),%rdx                              #! EA = L0x62c080
	mov    0x8(%rsi),%r14                           #! EA = L0x62c088
	mov    0x10(%rsi),%r15                          #! EA = L0x62c090
	mov    0x18(%rsi),%r8                           #! EA = L0x62c098
#	lea    -0x80(%rsi),%rsi                         #! EA = L0x62c000
#	#callq  0x427c00 <__ecp_nistz256_sqr_montx>
	mulx   %r14,%r9,%r10
	mulx   %r15,%rcx,%r11
	xor    %eax,%eax
	adc    %rcx,%r10
	mulx   %r8,%rbp,%r12
	mov    %r14,%rdx
	adc    %rbp,%r11
	adc    $0x0,%r12
	xor    %r13,%r13
	mulx   %r15,%rcx,%rbp
	adcx   %rcx,%r11
	adox   %rbp,%r12
	mulx   %r8,%rcx,%rbp
	mov    %r15,%rdx
	adcx   %rcx,%r12
	adox   %rbp,%r13
	adc    $0x0,%r13
	mulx   %r8,%rcx,%r14
	mov    0x80(%rsi),%rdx                          #! EA = L0x62c080
	xor    %r15,%r15
	adcx   %r9,%r9
	adox   %rcx,%r13
	adcx   %r10,%r10
	adox   %r15,%r14
	mulx   %rdx,%r8,%rbp
	mov    0x88(%rsi),%rdx                          #! EA = L0x62c088
	adcx   %r11,%r11
	adox   %rbp,%r9
	adcx   %r12,%r12
	mulx   %rdx,%rcx,%rax
	mov    0x90(%rsi),%rdx                          #! EA = L0x62c090
	adcx   %r13,%r13
	adox   %rcx,%r10
	adcx   %r14,%r14
	addr32 mulx %rdx,%rcx,%rbp
	mov    0x98(%rsi),%rdx                          #! EA = L0x62c098
	adox   %rax,%r11
	adcx   %r15,%r15
	adox   %rcx,%r12
	mov    $0x20,%rsi
	adox   %rbp,%r13
	addr32 addr32 mulx %rdx,%rcx,%rax
	mov    -0xccf(%rip),%rdx        # 0x427018      #! EA = L0x427018
	adox   %rcx,%r14
	shlx   %rsi,%r8,%rcx
	adox   %rax,%r15
	shrx   %rsi,%r8,%rax
	mov    %rdx,%rbp
	add    %rcx,%r9
	adc    %rax,%r10
	mulx   %r8,%rcx,%r8
	adc    %rcx,%r11
	shlx   %rsi,%r9,%rcx
	adc    $0x0,%r8
	shrx   %rsi,%r9,%rax
	add    %rcx,%r10
	adc    %rax,%r11
	mulx   %r9,%rcx,%r9
	adc    %rcx,%r8
	shlx   %rsi,%r10,%rcx
	adc    $0x0,%r9
	shrx   %rsi,%r10,%rax
	add    %rcx,%r11
	adc    %rax,%r8
	mulx   %r10,%rcx,%r10
	adc    %rcx,%r9
	shlx   %rsi,%r11,%rcx
	adc    $0x0,%r10
	shrx   %rsi,%r11,%rax
	add    %rcx,%r8
	adc    %rax,%r9
	mulx   %r11,%rcx,%r11
	adc    %rcx,%r10
	adc    $0x0,%r11
	xor    %rdx,%rdx
	add    %r8,%r12
	mov    -0xd6b(%rip),%rsi        # 0x427008      #! EA = L0x427008
	adc    %r9,%r13
	mov    %r12,%r8
	adc    %r10,%r14
	adc    %r11,%r15
	mov    %r13,%r9
	adc    $0x0,%rdx
#	sub    $0xffffffffffffffff,%r12
#	mov    %r14,%r10
#	sbb    %rsi,%r13
#	sbb    $0x0,%r14
#	mov    %r15,%r11
#	sbb    %rbp,%r15
#	sbb    $0x0,%rdx
#	cmovb  %r8,%r12
#	cmovb  %r9,%r13
#	mov    %r12,(%rdi)                              #! EA = L0x7fffffffd6d0
#	cmovb  %r10,%r14
#	mov    %r13,0x8(%rdi)                           #! EA = L0x7fffffffd6d8
#	cmovb  %r11,%r15
#	mov    %r14,0x10(%rdi)                          #! EA = L0x7fffffffd6e0
#	mov    %r15,0x18(%rdi)                          #! EA = L0x7fffffffd6e8
#	#repz retq 
#	mov    (%rsp),%r15                              #! EA = L0x7fffffffd698
#	mov    0x8(%rsp),%r14                           #! EA = L0x7fffffffd6a0
#	mov    0x10(%rsp),%r13                          #! EA = L0x7fffffffd6a8
#	mov    0x18(%rsp),%r12                          #! EA = L0x7fffffffd6b0
#	mov    0x20(%rsp),%rbx                          #! EA = L0x7fffffffd6b8
#	mov    0x28(%rsp),%rbp                          #! EA = L0x7fffffffd6c0
#	lea    0x30(%rsp),%rsp                          #! EA = L0x7fffffffd6c8
#	#repz retq 
